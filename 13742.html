<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Tensorflow 实战 (二)——MNIST（CNN 实现） | 陈泽豪</title><meta name="author" content="陈泽豪"><meta name="copyright" content="陈泽豪"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="原文链接：https:&#x2F;&#x2F;my.oschina.net&#x2F;u&#x2F;876354&#x2F;blog&#x2F;1926060 本文在原文基础上进行细微的修改和完善。  关于 MNIST 的介绍可以参考《Tensorflow 入门 (八)——MNIST》  在构建 AI 模型时，一般有以下主要步骤：准备数据、数据预处理、划分数据集、配置模型、训练模型、评估优化、模型应用，如下图所示：   下面将按照主要步骤进行介绍。 **">
<meta property="og:type" content="article">
<meta property="og:title" content="Tensorflow 实战 (二)——MNIST（CNN 实现）">
<meta property="og:url" content="https://chenzehao.com/13742.html">
<meta property="og:site_name" content="陈泽豪">
<meta property="og:description" content="原文链接：https:&#x2F;&#x2F;my.oschina.net&#x2F;u&#x2F;876354&#x2F;blog&#x2F;1926060 本文在原文基础上进行细微的修改和完善。  关于 MNIST 的介绍可以参考《Tensorflow 入门 (八)——MNIST》  在构建 AI 模型时，一般有以下主要步骤：准备数据、数据预处理、划分数据集、配置模型、训练模型、评估优化、模型应用，如下图所示：   下面将按照主要步骤进行介绍。 **">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">
<meta property="article:published_time" content="2020-08-14T16:00:00.000Z">
<meta property="article:modified_time" content="2022-01-21T05:50:26.320Z">
<meta property="article:author" content="陈泽豪">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><link rel="shortcut icon" href="https://tva1.sinaimg.cn/large/008i3skNgy1gyk8f9yfnqj305k05kglg.jpg"><link rel="canonical" href="https://chenzehao.com/13742"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><meta name="baidu-site-verification" content="code-GhGfwpqKHn"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?9191e58322566f7fdcbb360b8eeb1686";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'mediumZoom',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Tensorflow 实战 (二)——MNIST（CNN 实现）',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-01-21 13:50:26'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.0.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gyk8f9yfnqj305k05kglg.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">91</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">29</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><span> 笔记</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">陈泽豪</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><span> 笔记</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Tensorflow 实战 (二)——MNIST（CNN 实现）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-08-14T16:00:00.000Z" title="发表于 2020-08-15 00:00:00">2020-08-15</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-01-21T05:50:26.320Z" title="更新于 2022-01-21 13:50:26">2022-01-21</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">4.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>16分钟</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p> 原文链接：<a target="_blank" rel="noopener" href="https://my.oschina.net/u/876354/blog/1926060">https://my.oschina.net/u/876354/blog/1926060</a><br>
本文在原文基础上进行细微的修改和完善。</p>
<p> 关于 MNIST 的介绍可以参考《<a target="_blank" rel="noopener" href="https://editor.csdn.net/md/?articleId=107878416">Tensorflow 入门 (八)——MNIST</a>》</p>
<p> 在构建 AI 模型时，一般有以下主要步骤：准备数据、数据预处理、划分数据集、配置模型、训练模型、评估优化、模型应用，如下图所示：</p>
<p><img src="https://oscimg.oschina.net/oscnet/9c4d61b2595dac34bbc6f012e04621f1a8f.jpg" alt="9c4d61b2595dac34bbc6f012e04621f1a8f.jpg"></p>
<p> 下面将按照主要步骤进行介绍。</p>
<p>** 注意：** 由于 MNIST 数据集太经典了，很多深度学习书籍在介绍该入门模型案例时，基本上就是直接下载获取数据，然后就进行模型训练，最后得出一个准确率出来。但这样的入门案例学习后，当要拿自己的数据来训练模型，却往往不知该如何处理数据、如何训练、如何应用。在本文，将分两种情况进行介绍：<br>
（1）使用 MNIST 数据（本案例）<br>
（2）使用自己的数据。</p>
<p> 下面将针对模型训练的各个主要环节进行介绍，便于读者快速迁移去训练自己的数据模型。</p>
<h2 id="1- 准备数据">1. 准备数据 </h2>
<p> 准备数据是训练模型的第一步，基础数据可以是网上公开的数据集，也可以是自己的数据集。视觉、语音、语言等各种类型的数据在网上都能找到相应的数据集。</p>
<p><strong>（1）使用 MNIST 数据（本案例）</strong><br>
MNIST 数据集由于非常经典，已集成在 tensorflow 里面，可以直接加载使用，也可以从 MNIST 的官网上（<a target="_blank" rel="noopener" href="http://yann.lecun.com/exdb/mnist/%EF%BC%89">http://yann.lecun.com/exdb/mnist/）</a> 直接下载数据集，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从 tensorflow.examples.tutorials.mnist 引入模块。这是 TensorFlow 为了教学 MNIST 而提前编制的程序 </span></span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从 MNIST_data/ 中读取 MNIST 数据。这条语句在数据不存在时，会自动执行下载 </span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">&#x27;MNIST_data/&#x27;</span>, one_hot=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p> 集成或下载的 MNIST 数据集已经是打好标签了，直接使用就行。</p>
<p><strong>（2）使用自己的数据 </strong><br>
如果是使用自己的数据集，在准备数据时的重要工作是“标注数据”，也就是对数据进行打标签，主要的标注方式有：<br>
<strong>① 整个文件打标签 </strong>。例如 MNIST 数据集，每个图像只有 1 个数字，可以从 0 至 9 建 10 个文件夹，里面放相应数字的图像；也可以定义一个规则对图像进行命名，如按标签 + 序号命名；还可以在数据库里面创建一张对应表，存储文件名与标签之间的关联关系。如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/68a5fa875c11c8d082e774ec5ca1f7f2bc3.jpg" alt="68a5fa875c11c8d082e774ec5ca1f7f2bc3.jpg"></p>
<p><strong>② 圈定区域打标签 </strong>。例如 ImageNet 的物体识别数据集，由于每张图片上有各种物体，这些物体位于不同位置，因此需要圈定某个区域进行标注，目前比较流行的是 VOC2007、VOC2012 数据格式，这是使用 xml 文件保存图片中某个物体的名称（name）和位置信息（xmin,ymin,xmax,ymax）。<br>
如果图片很多，一张一张去计算位置信息，然后编写 xml 文件，实在是太耗时耗力了。所幸，有一位大神开源了一个数据标注工具 labelImg（<a target="_blank" rel="noopener" href="https://github.com/tzutalin/labelImg%EF%BC%89%EF%BC%8C%E5%8F%AA%E8%A6%81%E5%9C%A8%E7%95%8C%E9%9D%A2%E4%B8%8A%E7%94%BB%E6%A1%86%E6%A0%87%E6%B3%A8%EF%BC%8C%E5%B0%B1%E8%83%BD%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90VOC%E6%A0%BC%E5%BC%8F%E7%9A%84xml%E6%96%87%E4%BB%B6%E4%BA%86%EF%BC%8C%E9%9D%9E%E5%B8%B8%E6%96%B9%E4%BE%BF%EF%BC%8C%E5%A6%82%E4%B8%8B%E5%9B%BE%E6%89%80%E7%A4%BA%EF%BC%9A">https://github.com/tzutalin/labelImg），只要在界面上画框标注，就能自动生成 VOC 格式的 xml 文件了，非常方便，如下图所示：</a></p>
<p><img src="https://oscimg.oschina.net/oscnet/b39be86d04be933653680700702924dc30d.jpg" alt="b39be86d04be933653680700702924dc30d.jpg"></p>
<p><strong>③ 数据截段打标签 </strong>。针对语音识别、文字识别等，有些是将数据截成一段一段的语音或句子，然后在另外的文件中记录对应的标签信息。</p>
<h2 id="2- 数据预处理">2. 数据预处理 </h2>
<p> 在准备好基础数据之后，需要根据模型需要对基础数据进行相应的预处理。</p>
<p><strong>（1）使用 MNIST 数据（本案例）</strong><br>
由于 MNIST 数据集的尺寸统一，只有黑白两种像素，无须再进行额外的预处理，直接拿来建模型就行。</p>
<p><strong>（2）使用自己的数据 </strong><br>
而如果是要训练自己的数据，根据模型需要一般要进行以下预处理：</p>
<p><img src="https://oscimg.oschina.net/oscnet/2e7ffa9a92c9c36c3df43cc271d5f267841.jpg" alt="2e7ffa9a92c9c36c3df43cc271d5f267841.jpg"></p>
<p>**a. 统一格式：** 即统一基础数据的格式，例如图像数据集，则全部统一为 jpg 格式；语音数据集，则全部统一为 wav 格式；文字数据集，则全部统一为 UTF-8 的纯文本格式等，方便模型的处理；</p>
<p>**b. 调整尺寸：** 根据模型的输入要求，将样本数据全部调整为统一尺寸。例如 LeNet 模型是 32x32，AlexNet 是 224x224，VGG 是 224x224 等；</p>
<p>**c. 灰度化：** 根据模型需要，有些要求输入灰度图像，有些要求输入 RGB 彩色图像；</p>
<p>**d. 去噪平滑：** 为提升输入图像的质量，对图像进行去噪平滑处理，可使用中值滤波器、高斯滤波器等进行图像的去噪处理。如果训练数据集的图像质量很好了，则无须作去噪处理；</p>
<p>**e. 其它处理：** 根据模型需要进行直方图均衡化、二值化、腐蚀、膨胀等相关的处理；</p>
<p>**f. 样本增强：** 有一种观点认为神经网络是靠数据喂出来的，如果能够增加训练数据的样本量，提供海量数据进行训练，则能够有效提升算法的质量。常见的样本增强方式有：水平翻转图像、随机裁剪、平移变换，颜色、光照变换等，如下图所示：</p>
<p><img src="https://oscimg.oschina.net/oscnet/d00c298a95e844188c3ec4a128106605096.jpg" alt="d00c298a95e844188c3ec4a128106605096.jpg"></p>
<h2 id="3- 划分数据集">3. 划分数据集 </h2>
<p> 在训练模型之前，需要将样本数据划分为训练集、测试集，有些情况下还会划分为训练集、测试集、验证集。</p>
<p><strong>（1）使用 MNIST 数据（本案例）</strong></p>
<p> 本案例要训练模型的 MNIST 数据集，已经提供了训练集、测试集，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 提取训练集、测试集 </span></span><br><span class="line">train_xdata = mnist.train.images</span><br><span class="line">test_xdata = mnist.test.images</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取标签数据 </span></span><br><span class="line">train_labels = mnist.train.labels</span><br><span class="line">test_labels = mnist.test.labels</span><br></pre></td></tr></table></figure>
<p><strong>（2）使用自己的数据 </strong><br>
如果是要划分自己的数据集，可使用 scikit-learn 工具进行划分，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机选取 75% 的数据作为训练样本，其余 25% 的数据作为测试样本 </span></span><br><span class="line"><span class="comment"># X_data：数据集 </span></span><br><span class="line"><span class="comment"># y_labels：数据集对应的标签 </span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X_data, y_labels, test_size=<span class="number">0.25</span>, random_state=<span class="number">33</span>)</span><br></pre></td></tr></table></figure>
<h2 id="4- 配置模型">4. 配置模型 </h2>
<p> 接下来是选择模型、配置模型参数，建议先阅读深度学习经典模型的文章，可以参考《<a target="_blank" rel="noopener" href="https://editor.csdn.net/md/?articleId=108010886">Tensorflow 入门 (六)——初识卷积神经网络（CNN）</a>》，便于快速掌握深度学习模型的相关知识。</p>
<p><strong>（1）选择模型 </strong><br>
本案例将采用 LeNet 模型来训练 MNIST 手写数字模型，LeNet 是一个经典卷积神经网络模型，结构简单，针对 MNIST 这种简单的数据集可达到比较好的效果，LeNet 模型的原理介绍请见文章《<a target="_blank" rel="noopener" href="https://editor.csdn.net/md/?articleId=108012562">Tensorflow 入门 (七)——CNN 经典模型：LeNet</a>》，网络结构图如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/84e967f4c179074ef393f3dd24671c67f12.jpg" alt="84e967f4c179074ef393f3dd24671c67f12.jpg"></p>
<p><strong>（2）设置参数 </strong><br>
在训练模型时，一般要设置的参数有：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">step_cnt = <span class="number">5000</span>         <span class="comment"># 训练模型的迭代步数 </span></span><br><span class="line">batch_size = <span class="number">100</span>        <span class="comment"># 每次迭代批量取样本数据的量 </span></span><br><span class="line">learning_rate = <span class="number">0.001</span>   <span class="comment"># 学习率 </span></span><br></pre></td></tr></table></figure>
<p> 除此之外还有卷积层权重和偏置、池化层权重、全联接层权重和偏置、优化函数等等，根据模型需要进行设置。</p>
<h2 id="5- 训练模型">5. 训练模型 </h2>
<p> 接下来便是根据选择好的模型，构建网络，然后开始训练。</p>
<p><strong>（1）构建模型 </strong><br>
本案例按照 LeNet 的网络模型结构，构建网络模型，网络结构如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/0f750c7dc321fdc81a024063adeb812ceb8.jpg" alt="0f750c7dc321fdc81a024063adeb812ceb8.jpg"></p>
<p> 代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练数据，占位符 </span></span><br><span class="line">x = tf.placeholder(<span class="string">&quot;float&quot;</span>, shape=[<span class="literal">None</span>, <span class="number">784</span>])</span><br><span class="line"><span class="comment"># 训练的标签数据，占位符 </span></span><br><span class="line">y_ = tf.placeholder(<span class="string">&quot;float&quot;</span>, shape=[<span class="literal">None</span>, <span class="number">10</span>])</span><br><span class="line"><span class="comment"># 将样本数据转为 28x28</span></span><br><span class="line">x_image = tf.reshape(x, [-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保留概率，用于 dropout 层 </span></span><br><span class="line">keep_prob = tf.placeholder(tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一层：卷积层 </span></span><br><span class="line"><span class="comment"># 卷积核尺寸为 5x5，通道数为 1，深度为 32，移动步长为 1，采用 ReLU 激励函数 </span></span><br><span class="line">conv1_weights = tf.get_variable(<span class="string">&quot;conv1_weights&quot;</span>, [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">32</span>], initializer=tf.truncated_normal_initializer(stddev=<span class="number">0.1</span>))</span><br><span class="line">conv1_biases = tf.get_variable(<span class="string">&quot;conv1_biases&quot;</span>, [<span class="number">32</span>], initializer=tf.constant_initializer(<span class="number">0.0</span>))</span><br><span class="line">conv1 = tf.nn.conv2d(x_image, conv1_weights, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line">relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_biases))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二层：最大池化层 </span></span><br><span class="line"><span class="comment"># 池化核的尺寸为 2x2，移动步长为 2，使用全 0 填充 </span></span><br><span class="line">pool1 = tf.nn.max_pool(relu1, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第三层：卷积层 </span></span><br><span class="line"><span class="comment"># 卷积核尺寸为 5x5，通道数为 32，深度为 64，移动步长为 1，采用 ReLU 激励函数 </span></span><br><span class="line">conv2_weights = tf.get_variable(<span class="string">&quot;conv2_weights&quot;</span>, [<span class="number">5</span>, <span class="number">5</span>, <span class="number">32</span>, <span class="number">64</span>], initializer=tf.truncated_normal_initializer(stddev=<span class="number">0.1</span>))</span><br><span class="line">conv2_biases = tf.get_variable(<span class="string">&quot;conv2_biases&quot;</span>, [<span class="number">64</span>], initializer=tf.constant_initializer(<span class="number">0.0</span>))</span><br><span class="line">conv2 = tf.nn.conv2d(pool1, conv2_weights, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line">relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_biases))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第四层：最大池化层 </span></span><br><span class="line"><span class="comment"># 池化核尺寸为 2x2, 移动步长为 2，使用全 0 填充 </span></span><br><span class="line">pool2 = tf.nn.max_pool(relu2, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第五层：全连接层 </span></span><br><span class="line">fc1_weights = tf.get_variable(<span class="string">&quot;fc1_weights&quot;</span>, [<span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>, <span class="number">1024</span>], initializer=tf.truncated_normal_initializer(stddev=<span class="number">0.1</span>))</span><br><span class="line">fc1_baises = tf.get_variable(<span class="string">&quot;fc1_baises&quot;</span>, [<span class="number">1024</span>], initializer=tf.constant_initializer(<span class="number">0.1</span>))</span><br><span class="line">pool2_vector = tf.reshape(pool2, [-<span class="number">1</span>, <span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>])</span><br><span class="line">fc1 = tf.nn.relu(tf.matmul(pool2_vector, fc1_weights) + fc1_baises)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Dropout 层（即按 keep_prob 的概率保留数据，其它丢弃），以防止过拟合 </span></span><br><span class="line">fc1_dropout = tf.nn.dropout(fc1, keep_prob)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第六层：全连接层 </span></span><br><span class="line"><span class="comment"># 神经元节点数 1024, 分类节点 10</span></span><br><span class="line">fc2_weights = tf.get_variable(<span class="string">&quot;fc2_weights&quot;</span>, [<span class="number">1024</span>, <span class="number">10</span>], initializer=tf.truncated_normal_initializer(stddev=<span class="number">0.1</span>))</span><br><span class="line">fc2_biases = tf.get_variable(<span class="string">&quot;fc2_biases&quot;</span>, [<span class="number">10</span>], initializer=tf.constant_initializer(<span class="number">0.1</span>))</span><br><span class="line">fc2 = tf.matmul(fc1_dropout, fc2_weights) + fc2_biases</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第七层：输出层 </span></span><br><span class="line">y_conv = tf.nn.softmax(fc2)</span><br></pre></td></tr></table></figure>
<p><strong>（2）训练模型 </strong><br>
在训练模型时，需要选择优化器，也就是说要告诉模型以什么策略来提升模型的准确率，一般是选择交叉熵损失函数，然后使用优化器在反向传播时最小化损失函数，从而使模型的质量在不断迭代中逐步提升。<br>
代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义交叉熵损失函数 </span></span><br><span class="line"><span class="comment"># y_ 为真实标签 </span></span><br><span class="line">cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择优化器，使优化器最小化损失函数 </span></span><br><span class="line">train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回模型预测的最大概率的结果，并与真实值作比较 </span></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y_conv, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用平均值来统计测试准确率 </span></span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型 </span></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line">model_dir = <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    tf.global_variables_initializer().run()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(step_cnt):</span><br><span class="line">        batch = mnist.train.next_batch(batch_size)</span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># 每迭代 100 步进行一次评估，输出结果，保存模型，便于及时了解模型训练进展 </span></span><br><span class="line">            train_accuracy = accuracy.<span class="built_in">eval</span>(feed_dict=&#123;x: batch[<span class="number">0</span>], y_: batch[<span class="number">1</span>], keep_prob: <span class="number">1.0</span>&#125;)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;step %d, training accuracy %g&quot;</span> % (step, train_accuracy))</span><br><span class="line">            saver.save(sess, model_dir + <span class="string">&#x27;/my_mnist_model.ctpk&#x27;</span>, global_step=step)</span><br><span class="line">        train_step.run(feed_dict=&#123;x: batch[<span class="number">0</span>], y_: batch[<span class="number">1</span>], keep_prob: <span class="number">0.8</span>&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用测试数据测试准确率 </span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;test accuracy %g&quot;</span> % accuracy.<span class="built_in">eval</span>(feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels, keep_prob: <span class="number">1.0</span>&#125;))</span><br></pre></td></tr></table></figure>
<p> 训练的结果如下，由于 MNIST 数据集比较简单，模型训练很快就达到 99% 的准确率，如下图所示：</p>
<p><img src="https://oscimg.oschina.net/oscnet/d085bed5a7e25a7cb032491dbae9d9f7bf2.jpg" alt="d085bed5a7e25a7cb032491dbae9d9f7bf2.jpg"></p>
<p> 模型训练后保存的结果如下图所示：</p>
<p><img src="https://oscimg.oschina.net/oscnet/07001c5e613ba06d453e0dc09adf8f6950d.jpg" alt="07001c5e613ba06d453e0dc09adf8f6950d.jpg"></p>
<h2 id="6- 评估优化">6. 评估优化 </h2>
<p> 在使用训练数据完成模型的训练之后，再使用测试数据进行测试，了解模型的泛化能力，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用测试数据测试准确率 </span></span><br><span class="line">test_acc = accuracy.<span class="built_in">eval</span>(feed_dict=&#123;x: test_xdata, y_: test_labels, keep_prob: <span class="number">1.0</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;test accuracy %g&quot;</span> % test_acc)</span><br></pre></td></tr></table></figure>
<p> 模型测试结果如下：</p>
<p><img src="https://oscimg.oschina.net/oscnet/5aa7696b891a6940773071bb929775cc113.jpg" alt="5aa7696b891a6940773071bb929775cc113.jpg"></p>
<h2 id="7- 模型应用">7. 模型应用 </h2>
<p> 模型训练完成后，将模型保存起来，当要实际应用时，则通过加载模型，输入图像进行应用。代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载 MNIST 模型 </span></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    saver.restore(sess, tf.train.latest_checkpoint(model_dir))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 随机提取 MNIST 测试集的一个样本数据和标签 </span></span><br><span class="line">    test_len = <span class="built_in">len</span>(mnist.test.images)</span><br><span class="line">    test_idx = random.randint(<span class="number">0</span>, test_len-<span class="number">1</span>)</span><br><span class="line">    x_image = mnist.test.images[test_idx]</span><br><span class="line">    y = np.argmax(mnist.test.labels[test_idx])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 跑模型进行识别 </span></span><br><span class="line">    y_conv = tf.argmax(y_conv, <span class="number">1</span>)</span><br><span class="line">    pred=sess.run(y_conv, feed_dict=&#123;x: [x_image], keep_prob: <span class="number">1.0</span>&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27; 正确：&#x27;</span>, y, <span class="string">&#x27;，预测：&#x27;</span>, pred[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p> 使用模型进行测试的结果如下图：</p>
<p><img src="https://oscimg.oschina.net/oscnet/94c6c1e2e54ac1d71f4470e896ae8f616d4.jpg" alt="94c6c1e2e54ac1d71f4470e896ae8f616d4.jpg"></p>
<p> 至此，一个完整的模型训练和应用的过程就介绍完了。</p>
<h2 id="8- 完整代码">8. 完整代码 </h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 基于 LeNet5 的 MNIST 手写数字识别模型 </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据集路径 </span></span><br><span class="line">data_dir = <span class="string">&#x27;MNIST_data/&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 自动下载 MNIST 数据集 </span></span><br><span class="line">mnist = input_data.read_data_sets(data_dir, one_hot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果自动下载失败，则手工从官网上下载 MNIST 数据集，然后进行加载 </span></span><br><span class="line"><span class="comment"># 下载地址  http://yann.lecun.com/exdb/mnist/</span></span><br><span class="line"><span class="comment"># mnist=input_data.read_data_sets(data_dir,one_hot=True)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取训练集、测试集 </span></span><br><span class="line">train_xdata = mnist.train.images</span><br><span class="line">test_xdata = mnist.test.images</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取标签数据 </span></span><br><span class="line">train_labels = mnist.train.labels</span><br><span class="line">test_labels = mnist.test.labels</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练数据，占位符 </span></span><br><span class="line">x = tf.placeholder(<span class="string">&quot;float&quot;</span>, shape=[<span class="literal">None</span>, <span class="number">784</span>])</span><br><span class="line"><span class="comment"># 训练的标签数据，占位符 </span></span><br><span class="line">y_ = tf.placeholder(<span class="string">&quot;float&quot;</span>, shape=[<span class="literal">None</span>, <span class="number">10</span>])</span><br><span class="line"><span class="comment"># 将样本数据转为 28x28</span></span><br><span class="line">x_image = tf.reshape(x, [-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保留概率，用于 dropout 层 </span></span><br><span class="line">keep_prob = tf.placeholder(tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型的相关参数 </span></span><br><span class="line">step_cnt = <span class="number">5000</span>  <span class="comment"># 训练模型的迭代次数 </span></span><br><span class="line">batch_size = <span class="number">100</span>  <span class="comment"># 每次迭代时，批量获取样本的数据量 </span></span><br><span class="line">learning_rate = <span class="number">0.001</span>  <span class="comment"># 学习率 </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型保存路径 </span></span><br><span class="line">model_dir = <span class="string">&#x27;model&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># LeNet5 网络模型 </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lenet_network</span>():</span></span><br><span class="line">    <span class="comment"># 第一层：卷积层 </span></span><br><span class="line">    <span class="comment"># 卷积核尺寸为 5x5，通道数为 1，深度为 32，移动步长为 1，采用 ReLU 激励函数 </span></span><br><span class="line">    conv1_weights = tf.get_variable(<span class="string">&quot;conv1_weights&quot;</span>, [<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">32</span>],</span><br><span class="line">                                    initializer=tf.truncated_normal_initializer(stddev=<span class="number">0.1</span>))</span><br><span class="line">    conv1_biases = tf.get_variable(<span class="string">&quot;conv1_biases&quot;</span>, [<span class="number">32</span>], initializer=tf.constant_initializer(<span class="number">0.0</span>))</span><br><span class="line">    conv1 = tf.nn.conv2d(x_image, conv1_weights, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line">    relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_biases))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第二层：最大池化层 </span></span><br><span class="line">    <span class="comment"># 池化核的尺寸为 2x2，移动步长为 2，使用全 0 填充 </span></span><br><span class="line">    pool1 = tf.nn.max_pool(relu1, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第三层：卷积层 </span></span><br><span class="line">    <span class="comment"># 卷积核尺寸为 5x5，通道数为 32，深度为 64，移动步长为 1，采用 ReLU 激励函数 </span></span><br><span class="line">    conv2_weights = tf.get_variable(<span class="string">&quot;conv2_weights&quot;</span>, [<span class="number">5</span>, <span class="number">5</span>, <span class="number">32</span>, <span class="number">64</span>],</span><br><span class="line">                                    initializer=tf.truncated_normal_initializer(stddev=<span class="number">0.1</span>))</span><br><span class="line">    conv2_biases = tf.get_variable(<span class="string">&quot;conv2_biases&quot;</span>, [<span class="number">64</span>], initializer=tf.constant_initializer(<span class="number">0.0</span>))</span><br><span class="line">    conv2 = tf.nn.conv2d(pool1, conv2_weights, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line">    relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_biases))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第四层：最大池化层 </span></span><br><span class="line">    <span class="comment"># 池化核尺寸为 2x2, 移动步长为 2，使用全 0 填充 </span></span><br><span class="line">    pool2 = tf.nn.max_pool(relu2, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第五层：全连接层 </span></span><br><span class="line">    fc1_weights = tf.get_variable(<span class="string">&quot;fc1_weights&quot;</span>, [<span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>, <span class="number">1024</span>],</span><br><span class="line">                                  initializer=tf.truncated_normal_initializer(stddev=<span class="number">0.1</span>))</span><br><span class="line">    fc1_baises = tf.get_variable(<span class="string">&quot;fc1_baises&quot;</span>, [<span class="number">1024</span>], initializer=tf.constant_initializer(<span class="number">0.1</span>))</span><br><span class="line">    pool2_vector = tf.reshape(pool2, [-<span class="number">1</span>, <span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>])</span><br><span class="line">    fc1 = tf.nn.relu(tf.matmul(pool2_vector, fc1_weights) + fc1_baises)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Dropout 层（即按 keep_prob 的概率保留数据，其它丢弃），以防止过拟合 </span></span><br><span class="line">    fc1_dropout = tf.nn.dropout(fc1, keep_prob)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第六层：全连接层 </span></span><br><span class="line">    fc2_weights = tf.get_variable(<span class="string">&quot;fc2_weights&quot;</span>, [<span class="number">1024</span>, <span class="number">10</span>],</span><br><span class="line">                                  initializer=tf.truncated_normal_initializer(stddev=<span class="number">0.1</span>))  <span class="comment"># 神经元节点数 1024, 分类节点 10</span></span><br><span class="line">    fc2_biases = tf.get_variable(<span class="string">&quot;fc2_biases&quot;</span>, [<span class="number">10</span>], initializer=tf.constant_initializer(<span class="number">0.1</span>))</span><br><span class="line">    fc2 = tf.matmul(fc1_dropout, fc2_weights) + fc2_biases</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第七层：输出层 </span></span><br><span class="line">    y_conv = tf.nn.softmax(fc2)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> y_conv</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型 </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span>():</span></span><br><span class="line">    <span class="comment"># 加载 LeNet5 网络结构 </span></span><br><span class="line">    y_conv = lenet_network()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义交叉熵损失函数 </span></span><br><span class="line">    <span class="comment"># y_ 为真实标签 </span></span><br><span class="line">    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 选择优化器，使优化器最小化损失函数 </span></span><br><span class="line">    train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回模型预测的最大概率的结果，并与真实值作比较 </span></span><br><span class="line">    correct_prediction = tf.equal(tf.argmax(y_conv, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 用平均值来统计测试准确率 </span></span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练模型 </span></span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        tf.global_variables_initializer().run()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(step_cnt):</span><br><span class="line">            batch = mnist.train.next_batch(batch_size)</span><br><span class="line">            <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># 每迭代 100 步进行一次评估，输出结果，保存模型，便于及时了解模型训练进展 </span></span><br><span class="line">                train_accuracy = accuracy.<span class="built_in">eval</span>(feed_dict=&#123;x: batch[<span class="number">0</span>], y_: batch[<span class="number">1</span>], keep_prob: <span class="number">1.0</span>&#125;)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;step %d, training accuracy %g&quot;</span> % (step, train_accuracy))</span><br><span class="line">                saver.save(sess, model_dir + <span class="string">&#x27;/my_mnist_model.ctpk&#x27;</span>, global_step=step)</span><br><span class="line">            train_step.run(feed_dict=&#123;x: batch[<span class="number">0</span>], y_: batch[<span class="number">1</span>], keep_prob: <span class="number">0.8</span>&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 使用测试数据测试准确率 </span></span><br><span class="line">        test_acc = accuracy.<span class="built_in">eval</span>(feed_dict=&#123;x: test_xdata, y_: test_labels, keep_prob: <span class="number">1.0</span>&#125;)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;test accuracy %g&quot;</span> % test_acc)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型测试应用 </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_model</span>():</span></span><br><span class="line">    <span class="comment"># 加载 LeNet5 网络结构 </span></span><br><span class="line">    y_conv = lenet_network()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载 MNIST 模型 </span></span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        saver.restore(sess, tf.train.latest_checkpoint(model_dir))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 随机提取 MNIST 测试集的一个样本数据和标签 </span></span><br><span class="line">        test_len = <span class="built_in">len</span>(mnist.test.images)</span><br><span class="line">        test_idx = random.randint(<span class="number">0</span>, test_len - <span class="number">1</span>)</span><br><span class="line">        x_image = mnist.test.images[test_idx]</span><br><span class="line">        y = np.argmax(mnist.test.labels[test_idx])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 跑模型进行识别 </span></span><br><span class="line">        y_conv = tf.argmax(y_conv, <span class="number">1</span>)</span><br><span class="line">        pred = sess.run(y_conv, feed_dict=&#123;x: [x_image], keep_prob: <span class="number">1.0</span>&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27; 正确：&#x27;</span>, y, <span class="string">&#x27;，预测：&#x27;</span>, pred[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 训练模型 </span></span><br><span class="line">    train_model()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 测试应用模型 </span></span><br><span class="line">    <span class="comment"># test_model()</span></span><br></pre></td></tr></table></figure>
<p> 该代码运行后默认为训练模型，若要测试模型，则仅需将最后一段改为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 训练模型 </span></span><br><span class="line">    <span class="comment"># train_model()</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 测试应用模型 </span></span><br><span class="line">    test_model()</span><br></pre></td></tr></table></figure>
</article><div class="tag_share"><div class="post_share"><div class="social-share" data-image="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%20%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE"><span class="toc-text">1. 准备数据 </span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%20%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-text">2. 数据预处理 </span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%20%E5%88%92%E5%88%86%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-text">3. 划分数据集 </span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%20%E9%85%8D%E7%BD%AE%E6%A8%A1%E5%9E%8B"><span class="toc-text">4. 配置模型 </span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%20%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="toc-text">5. 训练模型 </span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%20%E8%AF%84%E4%BC%B0%E4%BC%98%E5%8C%96"><span class="toc-text">6. 评估优化 </span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%20%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8"><span class="toc-text">7. 模型应用 </span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-%20%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81"><span class="toc-text">8. 完整代码 </span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2021 - 2022 By 陈泽豪</div><div class="footer_custom_text">我是豪豪</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script></div></body></html>