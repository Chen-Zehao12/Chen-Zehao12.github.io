<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Tensorflow 入门 (六)——CNN 经典模型：LeNet | 陈泽豪</title><meta name="author" content="陈泽豪"><meta name="copyright" content="陈泽豪"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="原文链接：https:&#x2F;&#x2F;my.oschina.net&#x2F;u&#x2F;876354&#x2F;blog&#x2F;1632862  本文在原文基础上进行细微的修改和完善。   近几年来，卷积神经网络（Convolutional Neural Networks，简称 CNN）在图像识别中取得了非常成功的应用，成为深度学习的一大亮点。CNN 发展至今，已经有很多变种，其中有几个经典模型在 CNN 发展历程中有着里程碑的意义，它们">
<meta property="og:type" content="article">
<meta property="og:title" content="Tensorflow 入门 (六)——CNN 经典模型：LeNet">
<meta property="og:url" content="https://chenzehao.com/15018.html">
<meta property="og:site_name" content="陈泽豪">
<meta property="og:description" content="原文链接：https:&#x2F;&#x2F;my.oschina.net&#x2F;u&#x2F;876354&#x2F;blog&#x2F;1632862  本文在原文基础上进行细微的修改和完善。   近几年来，卷积神经网络（Convolutional Neural Networks，简称 CNN）在图像识别中取得了非常成功的应用，成为深度学习的一大亮点。CNN 发展至今，已经有很多变种，其中有几个经典模型在 CNN 发展历程中有着里程碑的意义，它们">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">
<meta property="article:published_time" content="2020-08-13T16:00:00.000Z">
<meta property="article:modified_time" content="2022-01-21T05:50:49.630Z">
<meta property="article:author" content="陈泽豪">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><link rel="shortcut icon" href="https://tva1.sinaimg.cn/large/008i3skNgy1gyk8f9yfnqj305k05kglg.jpg"><link rel="canonical" href="https://chenzehao.com/15018"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><meta name="baidu-site-verification" content="code-GhGfwpqKHn"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?9191e58322566f7fdcbb360b8eeb1686";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'mediumZoom',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Tensorflow 入门 (六)——CNN 经典模型：LeNet',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-01-21 13:50:49'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.0.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://tva1.sinaimg.cn/large/008i3skNgy1gyk8f9yfnqj305k05kglg.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">84</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">23</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><span> 笔记</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">陈泽豪</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><span> 笔记</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Tensorflow 入门 (六)——CNN 经典模型：LeNet</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-08-13T16:00:00.000Z" title="发表于 2020-08-14 00:00:00">2020-08-14</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-01-21T05:50:49.630Z" title="更新于 2022-01-21 13:50:49">2022-01-21</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">2.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>9分钟</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p> 原文链接：<a target="_blank" rel="noopener" href="https://my.oschina.net/u/876354/blog/1632862">https://my.oschina.net/u/876354/blog/1632862</a></p>
<p> 本文在原文基础上进行细微的修改和完善。</p>
<p><img src="https://static.oschina.net/uploads/space/2018/0311/012810_naQu_876354.png" alt="012810_naQu_876354.png"></p>
<p> 近几年来，卷积神经网络（Convolutional Neural Networks，简称 CNN）在图像识别中取得了非常成功的应用，成为深度学习的一大亮点。CNN 发展至今，已经有很多变种，其中有几个经典模型在 CNN 发展历程中有着里程碑的意义，它们分别是：LeNet、Alexnet、Googlenet、VGG、DRL 等。</p>
<p> 本文将介绍 CNN 经典模型之 LeNet</p>
<p> 在此简单回顾一下 CNN 的几个特点：<strong> 局部感知、参数共享、池化 </strong>。</p>
<h2 id="1-CNN 的三个特点">1. CNN 的三个特点 </h2>
<h3 id="1-1- 局部感知">1.1 局部感知 </h3>
<p> 人类对外界的认知一般是从局部到全局、从片面到全面，类似的，在机器识别图像时也没有必要把整张图像按像素全部都连接到神经网络中，在图像中也是局部周边的像素联系比较紧密，而距离较远的像素则相关性较弱，因此可以采用局部连接的模式（将图像分块连接，这样能大大减少模型的参数），如下图所示：</p>
<p><img src="https://static.oschina.net/uploads/space/2018/0311/012842_Z2z8_876354.png" alt="012842_Z2z8_876354.png"></p>
<h3 id="1-2- 参数（权值）共享">1.2 参数（权值）共享 </h3>
<p> 每张自然图像（人物、山水、建筑等）都有其固有特性，也就是说，图像其中一部分的统计特性与其它部分是接近的。这也意味着这一部分学习的特征也能用在另一部分上，能使用同样的学习特征。因此，在局部连接中隐藏层的每一个神经元连接的局部图像的权值参数（例如 5×5），将这些权值参数共享给其它剩下的神经元使用，那么此时不管隐藏层有多少个神经元，需要训练的参数就是这个局部图像的权限参数（例如 5×5），也就是卷积核的大小，这样大大减少了训练参数。如下图 </p>
<p><img src="https://static.oschina.net/uploads/space/2018/0311/012854_DfxF_876354.png" alt="012854_DfxF_876354.png"></p>
<h3 id="1-3- 池化">1.3 池化 </h3>
<p> 随着模型网络不断加深，卷积核越来越多，要训练的参数还是很多，而且直接拿卷积核提取的特征直接训练也容易出现过拟合的现象。回想一下，之所以对图像使用卷积提取特征是因为图像具有一种“静态性”的属性，因此，一个很自然的想法就是对不同位置区域提取出有代表性的特征（进行聚合统计，例如最大值、平均值等），这种聚合的操作就叫做池化，池化的过程通常也被称为特征映射的过程（特征降维），如下图：</p>
<p><img src="https://static.oschina.net/uploads/space/2018/0311/012904_j6uj_876354.png" alt="012904_j6uj_876354.png"></p>
<h2 id="2-LeNet5">2. LeNet5</h2>
<p> 回顾了卷积神经网络（CNN）上面的三个特点后，下面来介绍一下 CNN 的经典模型：<strong> 手写字体识别模型 LeNet5</strong>。</p>
<p>LeNet5 诞生于 1994 年，是最早的卷积神经网络之一， 由 Yann LeCun 完成，推动了深度学习领域的发展。在那时候，没有 GPU 帮助训练模型，甚至 CPU 的速度也很慢，因此，LeNet5 通过巧妙的设计，利用卷积、参数共享、池化等操作提取特征，避免了大量的计算成本，最后再使用全连接神经网络进行分类识别，这个网络也是最近大量神经网络架构的起点，给这个领域带来了许多灵感。</p>
<p>LeNet5 的网络结构示意图如下所示：</p>
<p><img src="https://static.oschina.net/uploads/space/2018/0311/012923_Ficx_876354.png" alt="012923_Ficx_876354.png"></p>
<p>LeNet5 由 7 层 CNN（不包含输入层）组成，上图中输入的原始图像大小是 32×32 像素，卷积层用 Ci 表示，子采样层（pooling，池化）用 Si 表示，全连接层用 Fi 表示。下面逐层介绍其作用和示意图上方的数字含义。</p>
<h3 id="2-1-C1 层（卷积层）：6-28×28">2.1 C1 层（卷积层）：6@28×28</h3>
<p> 该层使用了 6 个卷积核，每个卷积核的大小为 5×5，这样就得到了 6 个 feature map（特征图）。</p>
<p><strong>（1）特征图大小 </strong><br>
每个卷积核（5×5）与原始的输入图像（32×32）进行卷积，这样得到的 feature map（特征图）大小为（32-5+1）×（32-5+1）= 28×28<br>
卷积过程如下图所示：</p>
<p><img src="https://static.oschina.net/uploads/space/2018/0311/012939_tG24_876354.png" alt="012939_tG24_876354.png"></p>
<p> 卷积核与输入图像按卷积核大小逐个区域进行匹配计算，匹配后原始输入图像的尺寸将变小，因为边缘部分卷积核无法越出界，只能匹配一次，如上图，匹配计算后的尺寸变为 Cr×Cc=（Ir-Kr+1）×（Ic-Kc+1），其中 Cr、Cc，Ir、Ic，Kr、Kc 分别表示卷积后结果图像、输入图像、卷积核的行列大小。</p>
<p><strong>（2）参数个数 </strong><br>
由于参数（权值）共享的原因，对于同个卷积核每个神经元均使用相同的参数，因此，参数个数为（5×5+1）×6= 156，其中 5×5 为卷积核参数，1 为偏置参数 </p>
<p><strong>（3）连接数 </strong><br>
卷积后的图像大小为 28×28，因此每个特征图有 28×28 个神经元，每个卷积核参数为（5×5+1）×6，因此，该层的连接数为（5×5+1）×6×28×28=122304</p>
<h3 id="2-2-S2 层（下采样层，也称池化层）：6-14×14">2.2 S2 层（下采样层，也称池化层）：6@14×14</h3>
<p><strong>（1）特征图大小 </strong><br>
这一层主要是做池化或者特征映射（特征降维），池化单元为 2×2，因此，6 个特征图的大小经池化后即变为 14×14。回顾本文刚开始讲到的池化操作，池化单元之间没有重叠，在池化区域内进行聚合统计后得到新的特征值，因此经 2×2 池化后，每两行两列重新算出一个特征值出来，相当于图像大小减半，因此卷积后的 28×28 图像经 2×2 池化后就变为 14×14。</p>
<p> 这一层的计算过程是：2×2 单元里的值相加，然后再乘以训练参数 w，再加上一个偏置参数 b（每一个特征图共享相同的 w 和 b)，然后取 sigmoid 值（S 函数：0-1 区间），作为对应的该单元的值。卷积操作与池化的示意图如下：</p>
<p><img src="https://static.oschina.net/uploads/space/2018/0311/012957_l7Oh_876354.png" alt="012957_l7Oh_876354.png"></p>
<p><strong>（2）参数个数 </strong><br>
S2 层由于每个特征图都共享相同的 w 和 b 这两个参数，因此需要 2×6=12 个参数 </p>
<p><strong>（3）连接数 </strong><br>
下采样之后的图像大小为 14×14，因此 S2 层的每个特征图有 14×14 个神经元，每个池化单元连接数为 2×2+1（1 为偏置量），因此，该层的连接数为（2×2+1）×14×14×6 = 5880</p>
<h3 id="2-3-C3 层（卷积层）：16-10×10">2.3 C3 层（卷积层）：16@10×10</h3>
<p>C3 层有 16 个卷积核，卷积模板大小为 5×5。</p>
<p><strong>（1）特征图大小 </strong><br>
与 C1 层的分析类似，C3 层的特征图大小为（14-5+1）×（14-5+1）= 10×10</p>
<p><strong>（2）参数个数 </strong><br>
需要注意的是，C3 与 S2 并不是全连接而是部分连接，有些是 C3 连接到 S2 三层、有些四层、甚至达到 6 层，通过这种方式提取更多特征，连接的规则如下表所示：</p>
<p><img src="https://static.oschina.net/uploads/space/2018/0311/013017_pIe9_876354.png" alt="013017_pIe9_876354.png"></p>
<p> 例如，第一列表示 C3 层的第 0 个特征图（feature map）只跟 S2 层的第 0、1 和 2 这三个 feature maps 相连接，计算过程为：用 3 个卷积模板分别与 S2 层的 3 个 feature maps 进行卷积，然后将卷积的结果相加求和，再加上一个偏置，再取 sigmoid 得出卷积后对应的 feature map 了。其它列也是类似（有些是 3 个卷积模板，有些是 4 个，有些是 6 个）。因此，C3 层的参数数目为（5×5×3+1）×6 +（5×5×4+1）×9 +5×5×6+1 = 1516</p>
<p><strong>（3）连接数 </strong><br>
卷积后的特征图大小为 10×10，参数数量为 1516，因此连接数为 1516×10×10= 151600</p>
<h2 id="2-4-S4（下采样层，也称池化层）：16-5×5">2.4 S4（下采样层，也称池化层）：16@5×5</h2>
<p><strong>（1）特征图大小 </strong><br>
与 S2 的分析类似，池化单元大小为 2×2，因此，该层与 C3 一样共有 16 个特征图，每个特征图的大小为 5×5。</p>
<p><strong>（2）参数数量 </strong><br>
与 S2 的计算类似，所需要参数个数为 16×2 = 32</p>
<p><strong>（3）连接数 </strong><br>
连接数为（2×2+1）×5×5×16 = 2000</p>
<h2 id="2-5-C5 层（卷积层）：120">2.5 C5 层（卷积层）：120</h2>
<p><strong>（1）特征图大小 </strong><br>
该层有 120 个卷积核，每个卷积核的大小仍为 5×5，因此有 120 个特征图。由于 S4 层的大小为 5×5，而该层的卷积核大小也是 5×5，因此特征图大小为（5-5+1）×（5-5+1）= 1×1。这样该层就刚好变成了全连接，这只是巧合，如果原始输入的图像比较大，则该层就不是全连接了。</p>
<p><strong>（2）参数个数 </strong><br>
与前面的分析类似，本层的参数数目为 120×（5×5×16+1） = 48120</p>
<p><strong>（3）连接数 </strong><br>
由于该层的特征图大小刚好为 1×1，因此连接数为 48120×1×1=48120</p>
<h2 id="2-6-F6 层（全连接层）：84">2.6 F6 层（全连接层）：84</h2>
<p><strong>（1）特征图大小 </strong><br>
F6 层有 84 个单元，之所以选这个数字的原因是来自于输出层的设计，对应于一个 7×12 的比特图，如下图所示，-1 表示白色，1 表示黑色，这样每个符号的比特图的黑白色就对应于一个编码。</p>
<p><img src="https://static.oschina.net/uploads/space/2018/0311/013047_ApKN_876354.png" alt="013047_ApKN_876354.png"></p>
<p> 该层有 84 个特征图，特征图大小与 C5 一样都是 1×1，与 C5 层全连接。</p>
<p><strong>（2）参数个数 </strong><br>
由于是全连接，参数数量为（120+1）×84=10164。跟经典神经网络一样，F6 层计算输入向量和权重向量之间的点积，再加上一个偏置，然后将其传递给 sigmoid 函数得出结果。</p>
<p><strong>（3）连接数 </strong><br>
由于是全连接，连接数与参数数量一样，也是 10164。</p>
<h2 id="2-7-OUTPUT 层（输出层）：10">2.7 OUTPUT 层（输出层）：10</h2>
<p>Output 层也是全连接层，共有 10 个节点，分别代表数字 0 到 9。如果第 i 个节点的值为 0，则表示网络识别的结果是数字 i。</p>
<p><strong>（1）特征图大小 </strong><br>
该层采用径向基函数（RBF）的网络连接方式，假设 x 是上一层的输入，y 是 RBF 的输出，则 RBF 输出的计算方式是：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>=</mo><munder><mo>∑</mo><mi>j</mi></munder><mo stretchy="false">(</mo><msub><mi>x</mi><mi>j</mi></msub><mo>−</mo><msub><mi>w</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">y_i=\sum_{j}(x_j-w_{ij})^2
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4638em;vertical-align:-1.4138em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4138em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1502em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p> 上式中的 W~ij~ 的值由 i 的比特图编码确定，i 从 0 到 9，j 取值从 0 到 7×12-1。RBF 输出的值越接近于 0，表示当前网络输入的识别结果与字符 i 越接近。</p>
<p><strong>（2）参数个数 </strong><br>
由于是全连接，参数个数为 84×10=840</p>
<p><strong>（3）连接数 </strong><br>
由于是全连接，连接数与参数个数一样，也是 840</p>
<p> 通过以上介绍，已经了解了 LeNet 各层网络的结构、特征图大小、参数数量、连接数量等信息，下图是识别数字 3 的过程，可对照上面介绍各个层的功能进行一一回顾：</p>
<p><img src="https://static.oschina.net/uploads/space/2018/0311/013117_gXns_876354.png" alt="013117_gXns_876354.png"></p>
</article><div class="tag_share"><div class="post_share"><div class="social-share" data-image="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-CNN%20%E7%9A%84%E4%B8%89%E4%B8%AA%E7%89%B9%E7%82%B9"><span class="toc-text">1. CNN 的三个特点 </span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%20%E5%B1%80%E9%83%A8%E6%84%9F%E7%9F%A5"><span class="toc-text">1.1 局部感知 </span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%20%E5%8F%82%E6%95%B0%EF%BC%88%E6%9D%83%E5%80%BC%EF%BC%89%E5%85%B1%E4%BA%AB"><span class="toc-text">1.2 参数（权值）共享 </span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-%20%E6%B1%A0%E5%8C%96"><span class="toc-text">1.3 池化 </span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-LeNet5"><span class="toc-text">2. LeNet5</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-C1%20%E5%B1%82%EF%BC%88%E5%8D%B7%E7%A7%AF%E5%B1%82%EF%BC%89%EF%BC%9A6-28%C3%9728"><span class="toc-text">2.1 C1 层（卷积层）：6@28×28</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-S2%20%E5%B1%82%EF%BC%88%E4%B8%8B%E9%87%87%E6%A0%B7%E5%B1%82%EF%BC%8C%E4%B9%9F%E7%A7%B0%E6%B1%A0%E5%8C%96%E5%B1%82%EF%BC%89%EF%BC%9A6-14%C3%9714"><span class="toc-text">2.2 S2 层（下采样层，也称池化层）：6@14×14</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-C3%20%E5%B1%82%EF%BC%88%E5%8D%B7%E7%A7%AF%E5%B1%82%EF%BC%89%EF%BC%9A16-10%C3%9710"><span class="toc-text">2.3 C3 层（卷积层）：16@10×10</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-4-S4%EF%BC%88%E4%B8%8B%E9%87%87%E6%A0%B7%E5%B1%82%EF%BC%8C%E4%B9%9F%E7%A7%B0%E6%B1%A0%E5%8C%96%E5%B1%82%EF%BC%89%EF%BC%9A16-5%C3%975"><span class="toc-text">2.4 S4（下采样层，也称池化层）：16@5×5</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-5-C5%20%E5%B1%82%EF%BC%88%E5%8D%B7%E7%A7%AF%E5%B1%82%EF%BC%89%EF%BC%9A120"><span class="toc-text">2.5 C5 层（卷积层）：120</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-6-F6%20%E5%B1%82%EF%BC%88%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%EF%BC%89%EF%BC%9A84"><span class="toc-text">2.6 F6 层（全连接层）：84</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-7-OUTPUT%20%E5%B1%82%EF%BC%88%E8%BE%93%E5%87%BA%E5%B1%82%EF%BC%89%EF%BC%9A10"><span class="toc-text">2.7 OUTPUT 层（输出层）：10</span></a></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2021 - 2022 By 陈泽豪</div><div class="footer_custom_text">我是豪豪</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script></div></body></html>